# BaSyx DataBridge Files Generator (Python Version)

ğŸš€ **Automatic configuration files generator for BaSyx DataBridge synchronization**

This Python application automatically generates JSON configuration files for BaSyx DataBridge by reading Asset Administration Shell (AAS) submodels and creating the necessary protocol consumers, transformers, routes, and AAS server configurations.

## ğŸ”„ How It Works

1. **Submodel Configuration**: Submodel IDs are defined in the `.env` file (DATABRIDGE_ID, DATABRIDGE_ID_AID, DATABRIDGE_ID_AIMC)
2. **AAS Information Retrieval**: The application connects to the BaSyx AAS server and downloads detailed information about the configured submodels
3. **Configuration Generation**: Based on the submodel properties and data types, the application automatically generates:
   - Kafka/OPC UA/HTTP consumer configurations with UUID-based unique identifiers
   - JSONata transformers for data mapping
   - Route definitions for data flow
   - AAS server connection settings
4. **File Output**: All configuration files are saved in the `databridge_config_files/` directory, ready to be used by BaSyx DataBridge

## ğŸ“‹ AAS Examples

This project includes three comprehensive Asset Administration Shell (AAS) examples located in the `./aas/` directory, demonstrating different aspects of Industry 4.0 data integration:

### ğŸ¤– Robot AAS (`./aas/Robot.aasx`)
- **Purpose**: Defines the digital twin of an industrial robot
- **Data Sources**: Robot joint states, positions, velocities, and operational status
- **Integration**: Maps robot sensor data from Kafka topics to standardized AAS properties

### ğŸ”„ DataBridge AAS (`./aas/Databridge.aasx`)
- **Purpose**: Contains communication protocols, data mapping schemas, and transformation rules for data synchronization
- **Standard Submodels**: Includes AIMC (Asset Interface Mapping Configuration), AID (Asset Interface Description), and other submodels for interoperability
- **Protocol Support**: Kafka, OPC UA, HTTP protocol definitions
- **Data Flow**: Defines how data flows from Kafka topics to HTTP AAS server endpoints and integrates with standard submodels for seamless data exchange

### ğŸŒ Protocol Integration Architecture
The DataBridge AAS serves as the central coordination point:

```
Kafka Topics          DataBridge Python       BaSyx HTTP AAS Endpoints
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MPCM.joint_tool â”‚â”€â”€â–ºâ”‚ Protocol Mapper â”‚â”€â”€â”€â”€â–ºâ”‚ Robot AAS Properties   â”‚
â”‚ _states         â”‚   â”‚                 â”‚     â”‚                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚                 â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚                 â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PAM.body_track  â”‚â”€â”€â–ºâ”‚ Data Transform  â”‚â”€â”€â”€â”€â–ºâ”‚ Operator AAS Propertiesâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
## ğŸ”§ System Requirements

### Docker Execution (Recommended)
- **Docker** 20.10+  
- **Docker Compose** 1.29+  
- **Minimum 2GB RAM** for containers

### Local Python Execution
- **Python 3.11+**
- **pip** or **conda** for package management
- **Network access** to the BaSyx server specified in `.env`

## ğŸš€ Execution

### ğŸ³ Docker Execution (Recommended)

#### Docker services

This Docker Compose setup includes a complete Industry 4.0 data integration stack:

| Service | Purpose | Port | Description |
|---------|---------|------|-------------|
| **kafka-broker** | ğŸ“¡ Message Broker | 9092, 29092 | Apache Kafka message streaming platform |
| **aas-env** | ğŸ­ AAS Server | 8081 | BaSyx AAS Environment server for Asset Administration Shells |
| **databridge-configurator** | ğŸ“‹ Config Generator | - | Python-based generator for BaSyx DataBridge configuration files from AAS submodels |
| **databridge** | ğŸ”„ Data Bridge | - | BaSyx DataBridge service that consumes Kafka data and updates AAS properties |
| **aas-web-ui** | ğŸ–¥ï¸ Web Interface | 3000 | BaSyx AAS Web UI for monitoring and managing Asset Administration Shells |
| **robot-data-generator** | ğŸ¤– Robot Simulator | - | Publishes realistic robot joint state data to Kafka topic `MPCM.joint_tool_states` |

### ğŸ”„ Service Interaction Flow
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Generators     â”‚â”€â”€â”€â–ºâ”‚ Kafka Broker    â”‚â”€â”€â”€â–ºâ”‚ BaSyx DataBridgeâ”‚â”€â”€â”€â–ºâ”‚ AAS Environment â”‚â”€â”€â”€â–ºâ”‚ AAS Web UI          â”‚
â”‚ (Robot Simulator)   â”‚    â”‚ (Topics)        â”‚    â”‚ (Config Files)  â”‚    â”‚ (HTTP API)      â”‚    â”‚ (Monitor/Control)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

### ğŸš€ Complete System Startup
```bash
# Start all services in the correct order
docker-compose up -d

# Start databridge services
docker-compose --profile databridge up -d

# Check service health
docker-compose ps

# View logs from specific services
docker-compose logs -f databridge-configurator
docker-compose logs -f robot-data-generator
```

> **âš ï¸ IMPORTANT NOTE - Configuration Demonstration:**
> 
> The `Databridge.aasx` file contains **intentionally incorrect endpoints** to demonstrate the software's configuration generation functionality. To run the system correctly, you must:
> 
> 1. **Access the AAS Web UI** at http://localhost:3000
> 2. **Navigate to the DataBridge AAS** and locate the submodels
> 3. **Fix the Kafka Submodel**:
>    - Go to: **DataBridge** â†’ **AssetInterfacesDescription** â†’ **Kafka** â†’ **EndpointMetadata** â†’ **base**
>    - Change from `"kafka-broke"` to `"kafka-broker:29092"`
> 4. **Fix the HTTP Submodel**:
>    - Go to: **DataBridge** â†’ **AssetInterfacesDescription** â†’ **HTTP** â†’ **EndpointMetadata** â†’ **base**
>    - Change from `"aas-env"` to `"http://aas-env:8081"`
> 
> These corrections will trigger the configuration regeneration process and demonstrate how the system automatically updates when AAS submodel properties change.

### ğŸ Python Execution (Local Development)
```bash
# Clone the repository
git clone http://gitlab.aimen.local/iiot/converging/basyx-databridge-files-generator_python.git
cd basyx-databridge-files-generator_python

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.template .env
# Edit .env with your configuration

# Run the generator
python main.py
```

## âš™ï¸ Configuration

### Environment Variables

Copy the template and configure your environment:

```bash
# Copy template
cp .env.template .env

# Edit configuration
nano .env
```

The `.env` file contains the BaSyx server configurations and submodel identifiers:

```properties
BASE_URL=http://aas-env:8081
DATABRIDGE_ID=aHR0cHM6Ly93d3cuYWltZW4uZXMvYWFzL3h4bHBpbG90ZmFjdG9yeS9kYXRhYnJpZGdl
DATABRIDGE_ID_AID=aHR0cHM6Ly93d3cuYWltZW4uZXMvc20vYWlkL3h4bGlwaWxvdGZhY3RvcnkvZGF0YWJyaWRnZQ==
DATABRIDGE_ID_AIMC=aHR0cHM6Ly93d3cuYWltZW4uZXMvc20vYWltYy94eGxpcGlsb3RmYWN0b3J5L2RhdGFicmlkZ2U=
OUTPUT_DIR=databridge_config_files
```

| Variable | Description | Example |
|----------|-------------|---------|
| `BASE_URL` | BaSyx AAS server base URL | `"http://aas-env:8081"` |
| `DATABRIDGE_ID` | Main databridge submodel ID (base64) | `"aHR0cHM6Ly9...="` |
| `DATABRIDGE_ID_AID` | Asset Interfaces Description ID | `"eHhscGlsb3Q...="` |
| `DATABRIDGE_ID_AIMC` | Asset Interface Mapping Config ID | `"eHhscGlsb3Q...="` |
| `OUTPUT_DIR` | Output directory for generated files | `"databridge_config_files"` |

## ğŸ“ Generated Files for DataBridge service

Files are created in `databridge_config_files/`:

```
databridge_config_files/
â”œâ”€â”€ aasserver.json           # AAS Server configurations with UUID identifiers
â”œâ”€â”€ routes.json              # Routes configurations with UUID-based data sources
â”œâ”€â”€ jsonatatransformer.json  # JSONata transformers with UUID identifiers
â”œâ”€â”€ kafkaconsumer.json       # Kafka Consumer configurations (if applicable)
â”œâ”€â”€ opcuaconsumer.json       # OPC UA Consumer configurations (if applicable)
â”œâ”€â”€ mqttconsumer.json        # MQTT Consumer configurations (if applicable)
â””â”€â”€ *.json                   # Individual variable transformation files
```

## ï¿½ Project Structure

```
basyx-databridge-files-generator-python/
â”œâ”€â”€ main.py                          # ğŸš€ Main entry point
â”œâ”€â”€ service/
â”‚   â”œâ”€â”€ submodels.py                 # ğŸ” AAS submodel information handler
â”‚   â””â”€â”€ registryConnect.py           # ğŸŒ AAS registry connection utilities
â”œâ”€â”€ databridge_configurator/        # âš™ï¸ Configuration generation logic
â”‚   â”œâ”€â”€ configurationFiles.py       # ğŸ“ Main configuration file generator
â”‚   â”œâ”€â”€ topics.py                    # ğŸ¯ Topic data structures
â”‚   â””â”€â”€ models/                      # ğŸ“¦ Data model classes
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ routes_schema.py         # ğŸ›¤ï¸ Route configuration schema
â”‚       â”œâ”€â”€ protocol_schema.py       # ğŸ“¡ Protocol consumer schemas (Kafka, OPC UA, MQTT)
â”‚       â”œâ”€â”€ jsonatatransformer_schema.py # ğŸ”„ JSONata transformer schema
â”‚       â””â”€â”€ aasServerJson_schema.py  # ğŸ­ AAS server configuration schema
â”œâ”€â”€ aas/                             # ğŸ“ Example AAS files
â”‚   â”œâ”€â”€ Databridge.aasx             # ğŸ”„ DataBridge AAS with protocol configurations
â”‚   â””â”€â”€ Robot.aasx                  # ğŸ¤– Robot AAS with joint state definitions
â”œâ”€â”€ databridge_config_files/        # ğŸ“ Output directory for generated files (git ignored)
â”œâ”€â”€ logs/                            # ğŸ“ Application logs (git ignored)
â”œâ”€â”€ .env                             # ğŸ”‘ Environment variables (git ignored)
â”œâ”€â”€ .env.template                    # ğŸ”‘ Environment variable template
â”œâ”€â”€ .gitignore                       # ğŸš« Git ignore rules
â”œâ”€â”€ .dockerignore                    # ğŸ³ Docker ignore rules
â”œâ”€â”€ Dockerfile                       # ğŸ³ Docker build instructions
â”œâ”€â”€ docker-compose.yml               # ğŸ³ Docker Compose configuration
â”œâ”€â”€ requirements.txt                 # ğŸ“‹ Python dependencies
â””â”€â”€ README.md                        # ğŸ“– Project documentation
```

## ğŸ² Data Generators

This project integrates with complementary data generators that simulate realistic data sources for testing and development purposes:

### ğŸ¤– Robot Data Generator
- **Purpose**: Simulates industrial robot joint states and operational data
- **Data Types**: Joint positions, velocities, efforts, and operational states
- **Protocol**: Kafka messaging to topic `MPCM.joint_tool_states`
- **Format**: ROS-compatible sensor_msgs/JointState format
- **Features**: Realistic movement patterns, configurable publish rates

### ğŸ“¡ Integration with BaSyx DataBridge
The generated data flows through the following pipeline:
1. **Data Generators** â†’ Kafka Topics (`MPCM.joint_tool_states`)
2. **BaSyx DataBridge** â†’ Consumes Kafka data using Python-generated configuration files
3. **AAS Server** â†’ Exposes data through standardized Asset Administration Shell interface

### âš™ï¸ Generator Configuration
Each generator can be configured through environment variables:
- **KAFKA_BROKER**: Kafka broker connection string
- **PUBLISH_INTERVAL**: Data publishing frequency (seconds)
- **TOPIC_JOINT_STATES**: Robot joint states topic name

## ğŸ”§ Development

### Setting up development environment

```bash
# Clone repository
git clone http://gitlab.aimen.local/iiot/converging/basyx-databridge-files-generator_python.git

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or
venv\Scripts\activate     # Windows

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.template .env
# Edit .env with your configuration

# Run the generator
python main.py
```

### Code Architecture

- **Models**: Pydantic-based data classes representing configuration schemas
- **Services**: Business logic for submodel processing and AAS communication
- **Configurator**: File generation logic with UUID-based unique identifiers
- **Utils**: Helper functions for HTTP requests and data transformation

## ğŸ“š Dependencies

- `basyx-python-sdk`: Official BaSyx Python SDK for AAS operations
- `loguru`: Advanced logging with structured output
- `lxml`: XML processing for AAS file handling
- `requests`: HTTP client for BaSyx API communication
- `python-dotenv`: Environment variable management
- `pydantic`: Data validation and settings management
- `jsonpath_ng`: JSONPath expressions for data querying

## ğŸ™ Acknowledgments

This project is developed as part of the **CONVERGING** project, which aims to develop, deploy, validate, and promote smart and reconfigurable production systems including multiple autonomous agents (collaborative robots, AGVs, humans) that are able to act in diverse production environments.

ğŸŒ **Project Website**: [https://www.converging-project.eu/](https://www.converging-project.eu/)

ğŸ‡ªğŸ‡º **Funding**: The CONVERGING project is co-funded by the European Union's Horizon Europe Research & Innovation Programme under Grant NÂ° 101058521.

We acknowledge the support and contributions of all CONVERGING project partners and collaborators who have made this work possible.

## ğŸ“„ License

This project is licensed under review.

---

**ğŸš€ Ready to streamline your BaSyx DataBridge configuration? Get started now!**

```bash
# Docker execution (recommended)
docker-compose up -d
docker-compose --profile databridge up -d

# Or local Python execution
python main.py
```
